{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e9346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Data...\n",
      "2. Resampling to Monthly Sums...\n",
      "3. Processing SPI-1...\n",
      "3. Processing SPI-3...\n",
      "3. Processing SPI-6...\n",
      "3. Processing SPI-12...\n",
      "4. Saving Year-wise Files...\n",
      "  - Writing SPI_1991.nc...\n",
      "  - Writing SPI_1992.nc...\n",
      "  - Writing SPI_1993.nc...\n",
      "  - Writing SPI_1994.nc...\n",
      "  - Writing SPI_1995.nc...\n",
      "  - Writing SPI_1996.nc...\n",
      "  - Writing SPI_1997.nc...\n",
      "  - Writing SPI_1998.nc...\n",
      "  - Writing SPI_1999.nc...\n",
      "  - Writing SPI_2000.nc...\n",
      "  - Writing SPI_2001.nc...\n",
      "  - Writing SPI_2002.nc...\n",
      "  - Writing SPI_2003.nc...\n",
      "  - Writing SPI_2004.nc...\n",
      "  - Writing SPI_2005.nc...\n",
      "  - Writing SPI_2006.nc...\n",
      "  - Writing SPI_2007.nc...\n",
      "  - Writing SPI_2008.nc...\n",
      "  - Writing SPI_2009.nc...\n",
      "  - Writing SPI_2010.nc...\n",
      "  - Writing SPI_2011.nc...\n",
      "  - Writing SPI_2012.nc...\n",
      "  - Writing SPI_2013.nc...\n",
      "  - Writing SPI_2014.nc...\n",
      "  - Writing SPI_2015.nc...\n",
      "  - Writing SPI_2016.nc...\n",
      "  - Writing SPI_2017.nc...\n",
      "  - Writing SPI_2018.nc...\n",
      "  - Writing SPI_2019.nc...\n",
      "  - Writing SPI_2020.nc...\n",
      "  - Writing SPI_2021.nc...\n",
      "  - Writing SPI_2022.nc...\n",
      "  - Writing SPI_2023.nc...\n",
      "Done! Files saved in 'SPI_Output' folder.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings related to division by zero or log of zero during Gamma fitting\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =================CONFIGURATION =================\n",
    "# Update these variables to match your data\n",
    "INPUT_FOLDER = 'mon_rainfall'          # Current folder\n",
    "OUTPUT_FOLDER = 'drought_indices'\n",
    "VAR_NAME = 'monthly_rain'       # Name of the variable inside your .nc files\n",
    "FILE_PATTERN = '*.nc'       # Pattern to match your files (e.g. 1990.nc, 1991.nc)\n",
    "TIMESCALE_LIST = [1, 3, 6, 12]\n",
    "START_YEAR_OUTPUT = 1991\n",
    "END_YEAR_OUTPUT = 2023\n",
    "# ================================================\n",
    "\n",
    "def compute_spi_gamma(data_array):\n",
    "    \"\"\"\n",
    "    Computes SPI using Gamma distribution fitting.\n",
    "    Expects a 1D numpy array (time series for a specific pixel and specific month).\n",
    "    \"\"\"\n",
    "    # Remove NaNs\n",
    "    clean_data = data_array[~np.isnan(data_array)]\n",
    "    \n",
    "    if len(clean_data) < 3:\n",
    "        # Not enough data to fit\n",
    "        return np.full(data_array.shape, np.nan)\n",
    "\n",
    "    # SPI requires handling zeros separately (Gamma is undefined for 0)\n",
    "    zeros = clean_data == 0\n",
    "    non_zeros = clean_data[clean_data > 0]\n",
    "    \n",
    "    n = len(clean_data)\n",
    "    n_zeros = np.sum(zeros)\n",
    "    q = n_zeros / n  # Probability of zero\n",
    "    \n",
    "    if len(non_zeros) == 0:\n",
    "        # All rain is zero\n",
    "        # Probability is q (which is 1.0). \n",
    "        # In standard SPI, this is handled, but often maps to a specific minimum bound.\n",
    "        # We return a standard dry value or calculation based on q.\n",
    "        # Simple approach: standard normal of q\n",
    "        return np.full(data_array.shape, stats.norm.ppf(q))\n",
    "\n",
    "    # Fit Gamma distribution to non-zero values\n",
    "    # alpha (shape), loc, beta (scale)\n",
    "    alpha, loc, beta = stats.gamma.fit(non_zeros, floc=0)\n",
    "    \n",
    "    # Calculate Cumulative Probability\n",
    "    # 1. CDF of Gamma for observed values\n",
    "    y_gamma = stats.gamma.cdf(clean_data, alpha, loc=loc, scale=beta)\n",
    "    \n",
    "    # 2. Combined CDF considering zeros\n",
    "    # H(x) = q + (1-q) * G(x)\n",
    "    y_norm = q + (1 - q) * y_gamma\n",
    "    \n",
    "    # If y_norm is 1.0 (max), norm.ppf is inf. We clip slightly.\n",
    "    y_norm = np.clip(y_norm, 0, 0.99999)\n",
    "    \n",
    "    # 3. Convert probability to Z-score (SPI)\n",
    "    spi = stats.norm.ppf(y_norm)\n",
    "    \n",
    "    # We must return an array matching the original shape (including NaNs if any)\n",
    "    # However, xarray apply_ufunc handles the re-mapping if we return consistent shape\n",
    "    # Here we just return the calculated SPIs for the valid inputs\n",
    "    \n",
    "    # Reconstruct full array with NaNs if the input had NaNs \n",
    "    # (Though usually apply_ufunc passes clean slices if configured, \n",
    "    # basic apply passes the whole vector)\n",
    "    result = np.full(data_array.shape, np.nan)\n",
    "    result[~np.isnan(data_array)] = spi\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "    print(\"1. Loading Data...\")\n",
    "    # Load all files\n",
    "    ds = xr.open_mfdataset(os.path.join(INPUT_FOLDER, FILE_PATTERN), \n",
    "                           combine='by_coords', \n",
    "                           parallel=True, \n",
    "                           chunks={'time': -1, 'lat': 50, 'lon': 50}) \n",
    "\n",
    "    ds = ds.sortby('time')\n",
    "    \n",
    "    if VAR_NAME not in ds:\n",
    "        raise ValueError(f\"Variable '{VAR_NAME}' not found. Found: {list(ds.data_vars)}\")\n",
    "\n",
    "    print(\"2. Resampling to Monthly Sums...\")\n",
    "    precip_monthly = ds[VAR_NAME].resample(time='1MS').sum(skipna=False)\n",
    "    \n",
    "    # Force 'time' to be a single chunk to prevent the error\n",
    "    # This ensures the entire time history is available for the SPI calculation\n",
    "    precip_monthly = precip_monthly.chunk({'time': -1})\n",
    "\n",
    "    ds_spi = xr.Dataset()\n",
    "    ds_spi.coords.update(precip_monthly.coords)\n",
    "\n",
    "    for scale in TIMESCALE_LIST:\n",
    "        print(f\"3. Processing SPI-{scale}...\")\n",
    "        \n",
    "        # A. Calculate Rolling Sum\n",
    "        rolling_sum = precip_monthly.rolling(time=scale, center=False, min_periods=scale).sum()\n",
    "\n",
    "        # B. Calculate SPI\n",
    "        # We group by month (Januaries, Februarys...) and apply the SPI function\n",
    "        spi_da = rolling_sum.groupby('time.month').map(\n",
    "            lambda x: xr.apply_ufunc(\n",
    "                compute_spi_gamma, \n",
    "                x,\n",
    "                input_core_dims=[['time']],\n",
    "                output_core_dims=[['time']],\n",
    "                vectorize=True, \n",
    "                dask='parallelized',\n",
    "                output_dtypes=[float],\n",
    "                # --- THE FIX IS HERE ---\n",
    "                # This allows dask to merge time chunks if they became fragmented\n",
    "                dask_gufunc_kwargs={'allow_rechunk': True} \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Sort back to chronological order\n",
    "        spi_da = spi_da.sortby('time')\n",
    "        \n",
    "        ds_spi[f'spi_{scale}'] = spi_da\n",
    "\n",
    "    print(\"4. Saving Year-wise Files...\")\n",
    "    \n",
    "    # Select only the requested output years\n",
    "    ds_final = ds_spi.sel(time=slice(f'{START_YEAR_OUTPUT}-01-01', f'{END_YEAR_OUTPUT}-12-31'))\n",
    "\n",
    "    years = np.unique(ds_final['time.year'])\n",
    "    \n",
    "    for year in years:\n",
    "        ds_year = ds_final.sel(time=str(year))\n",
    "        \n",
    "        out_filename = f\"SPI_{year}.nc\"\n",
    "        out_path = os.path.join(OUTPUT_FOLDER, out_filename)\n",
    "        \n",
    "        print(f\"  - Writing {out_filename}...\")\n",
    "        ds_year.to_netcdf(out_path)\n",
    "\n",
    "    print(\"Done! Files saved in 'SPI_Output' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnet-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
